{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for classification on MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import MNIST datasets and labels from Keras.\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Extract the shape of the train and test datasets\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a few image samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[1])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_train[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Reshape the train and test dataset,28x28 = 784\n",
    "\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#cast datasets’ format to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize the datasets(values in [0,1])\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# transform the labels into class vectors \n",
    "#vectors containing a unique 1 indicating the class, other entries are 0\n",
    "from keras.utils import np_utils\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 1st neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "#initialize\n",
    "model = Sequential()\n",
    "\n",
    "#hidden layer\n",
    "model.add(Dense(256,input_shape=(784,))) \n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(10)) \n",
    "model.add(Activation('softmax')) # use softmax for multi-class targets\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the architecture of neural network\n",
    "!pip install pydot\n",
    "!pip install GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,show_shapes=True,  to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(filename='model.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number_of_weights = 784 x 256 + 256 x 10 = 203264\n",
    "##### Number_of_biases = 256 + 10 = 266\n",
    "##### Number of learnable parameters = 203264 + 266 = 203530"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='sgd')\n",
    "\n",
    "# Train the model for 10 epochs, with a batch size of 64 and \n",
    "#store the results in a handle. \n",
    "#Split the training set into a validation set and an actual training set. \n",
    "history=model.fit(x_train, y_train, epochs=10, batch_size=64,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot in the same figure the train/validation accuracy curves \n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures show that the loss on the training set is decreasing, which means the network is learning to classify the digits. However, the training loss is larger than the validation loss, and the loss curves could have continued more. Therefore, more epoches and bigger network are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Evaluation and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model with a batch size of 128 and \n",
    "#store the test loss and the test accuracy.\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into a .json file \n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "#save learned weights into a HDF5 file\n",
    "model.save_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （6） Experiment\n",
    "#### a) Compare sigmoid vs ReLU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create another model using ReLU activation\n",
    "model2 = Sequential()\n",
    "\n",
    "#hidden layer\n",
    "model2.add(Dense(256,input_shape=(784,))) \n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "#output layer\n",
    "model2.add(Dense(10)) \n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "#compile\n",
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='sgd')\n",
    "\n",
    "#train\n",
    "history2=model2.fit(x_train, y_train, epochs=10, batch_size=64,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_sigmoid', 'validation_sigmoid','train_relu','validation_relu'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_sigmoid', 'validation_sigmoid','train_relu','validation_relu'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that 'relu' leads to higher accuracy and smaller loss than 'sigmoid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
